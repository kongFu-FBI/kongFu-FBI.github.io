<!DOCTYPE html><html lang="zh-CN"><head><!-- hexo injector head_begin start --><link href="https://cdn.jsdelivr.net/npm/hexo-widget-tree@0.1.1/css/index.css" rel="stylesheet"/><!-- hexo injector head_begin end --><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="个人介绍"><meta name="copyright" content="个人介绍"><meta name="generator" content="Hexo 5.4.0"><meta name="theme" content="hexo-theme-yun"><title>jieba使用教程---自定义分词不起作用解决方法 | 本站介绍</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.24/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_j5gk85dg4pf.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", () => {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
});
</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script>document.addEventListener("DOMContentLoaded", () => {
  Yun.utils.renderKatex();
});</script><link class="aplayer-style-marker" rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script class="aplayer-script-marker" src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" defer></script><script class="meting-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/pjax@latest/pjax.min.js" defer></script><script src="/js/pjax.js" defer></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><link id="light-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism.css" media="(prefers-color-scheme: light)"><link id="dark-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism-tomorrow.css" media="(prefers-color-scheme: dark)"><link rel="icon" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"example.com","root":"/","title":"达拉崩吧的城堡","version":"1.6.1","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><meta name="description" content="jieba四种分词模式 精确模式，试图将句子最精确地切开，适合文本分析。 按照优先级只显示一次需要划分的词语。   全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义。 比如清华大学，会划词显示 清华&#x2F; 清华大学&#x2F; 华大&#x2F; 大学 四个词   搜索引擎模式，在精确模式的基础上，对长词再次切分。 如中国科学院计算所，会分词为 中国, 科学, 学院, 科学院, 中国科学院,">
<meta property="og:type" content="article">
<meta property="og:title" content="jieba使用教程---自定义分词不起作用解决方法">
<meta property="og:url" content="http://example.com/2021/11/05/jieba%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E8%AF%8D%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/index.html">
<meta property="og:site_name" content="本站介绍">
<meta property="og:description" content="jieba四种分词模式 精确模式，试图将句子最精确地切开，适合文本分析。 按照优先级只显示一次需要划分的词语。   全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义。 比如清华大学，会划词显示 清华&#x2F; 清华大学&#x2F; 华大&#x2F; 大学 四个词   搜索引擎模式，在精确模式的基础上，对长词再次切分。 如中国科学院计算所，会分词为 中国, 科学, 学院, 科学院, 中国科学院,">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-11-05T07:26:02.000Z">
<meta property="article:modified_time" content="2021-11-05T07:32:58.583Z">
<meta property="article:author" content="个人介绍">
<meta name="twitter:card" content="summary"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><canvas id="trianglifyContainer"></canvas><script defer src="https://cdn.jsdelivr.net/npm/trianglify@4/dist/trianglify.bundle.js"></script><script>document.addEventListener("DOMContentLoaded", () => {
  const pattern = trianglify({
    width: 800,
    height: 600,
    cellSize: 75,
    palette: ["YlGnBu", "GnBu", "Purples", "Blues"],
  });
  const canvasOpts = {
    applyCssScaling: false
  }
  document.body.appendChild(pattern.toCanvas(trianglifyContainer, canvasOpts));
});</script><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="个人介绍"><img width="96" loading="lazy" src="/images/hade.jpg" alt="个人介绍"><span class="site-author-status" title="不想上学">😭</span></a><div class="site-author-name"><a href="/about/">个人介绍</a></div><a class="site-name" href="/about/site.html">本站介绍</a><sub class="site-subtitle"></sub><div class="site-desciption"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">16</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">16</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">0</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="http://wpa.qq.com/msgrd?v=3&amp;uin=644907106&amp;site=qq&amp;menu=yes" title="QQ" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/kongFu-FBI" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:644907106@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/215083917" title="哔哩哔哩动画" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#jieba%E5%9B%9B%E7%A7%8D%E5%88%86%E8%AF%8D%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.</span> <span class="toc-text">jieba四种分词模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3API"><span class="toc-number">2.</span> <span class="toc-text">相关API</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%A1%88%E4%B8%80"><span class="toc-number"></span> <span class="toc-text">方案一</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90"><span class="toc-number">1.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%A7%E7%BB%AD%E6%B5%8B%E8%AF%95"><span class="toc-number">2.</span> <span class="toc-text">继续测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%A1%88%E4%BA%8C"><span class="toc-number"></span> <span class="toc-text">方案二</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number"></span> <span class="toc-text">结论</span></a></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://example.com/2021/11/05/jieba%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E8%AF%8D%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="个人介绍"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="本站介绍"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">jieba使用教程---自定义分词不起作用解决方法</h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2021-11-05 15:26:02" itemprop="dateCreated datePublished" datetime="2021-11-05T15:26:02+08:00">2021-11-05</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">2.6k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">11m</span></span></span><span class="post-busuanzi"><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span id="busuanzi_value_page_pv"></span></span></span><span class="leancloud_visitors" id="/2021/11/05/jieba%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E8%AF%8D%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/" data-flag-title="jieba使用教程---自定义分词不起作用解决方法"><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><span class="post-meta-divider">-</span><a href="#comment"><span class="post-meta-item-icon" title="评论数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-chat-3-line"></use></svg> <span class="waline-comment-count" id="/2021/11/05/jieba%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E8%AF%8D%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"></span></span></a><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">自然语言</span></a></span> > <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/jieba/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">jieba</span></a></span></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><h3 id="jieba四种分词模式"><a href="#jieba四种分词模式" class="headerlink" title="jieba四种分词模式"></a>jieba四种分词模式</h3><ul>
<li>精确模式，试图将句子最精确地切开，适合文本分析。<ul>
<li>按照优先级只显示一次需要划分的词语。</li>
</ul>
</li>
<li>全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义。<ul>
<li>比如清华大学，会划词显示 清华/ 清华大学/ 华大/ 大学 四个词</li>
</ul>
</li>
<li>搜索引擎模式，在精确模式的基础上，对长词再次切分。<ul>
<li>如中国科学院计算所，会分词为 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所。</li>
</ul>
</li>
<li>使用了Paddlepaddle框架，暂时跳过。</li>
</ul>
<p>根据任务需求，因为只需要将优先级高的特有名词显示一次即可，所以定位在<strong>精确模式</strong>。</p>
<h3 id="相关API"><a href="#相关API" class="headerlink" title="相关API"></a>相关API</h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token number">1</span><span class="token punctuation">.</span> 自定义词典
Tokenizer<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span>segment<span class="token punctuation">,</span> tune<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">int</span>
Suggest word frequency to force the characters <span class="token keyword">in</span> a word to be joined <span class="token keyword">or</span> splitted<span class="token punctuation">.</span>

Parameter<span class="token punctuation">:</span> <span class="token operator">-</span> segment <span class="token punctuation">:</span> The segments that the word <span class="token keyword">is</span> expected to be cut into<span class="token punctuation">,</span> If the word should be treated <span class="token keyword">as</span> a whole<span class="token punctuation">,</span> use a <span class="token builtin">str</span><span class="token punctuation">.</span> <span class="token operator">-</span> tune <span class="token punctuation">:</span> If <span class="token boolean">True</span><span class="token punctuation">,</span> tune the word frequency<span class="token punctuation">.</span>
<span class="token operator">-</span> 如果需要将两个词当成连贯的词语，则传入一个<span class="token builtin">str</span>。
<span class="token operator">-</span> 如果需要把一个词语中的两个词当成不同的词语，则传入一个元组。
<span class="token operator">-</span> tune设为<span class="token boolean">True</span>，表示启用。            
Note that HMM may affect the final result<span class="token punctuation">.</span> If the result doesn't change<span class="token punctuation">,</span> <span class="token builtin">set</span> HMM<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">.</span>
<span class="token number">2</span><span class="token punctuation">.</span>关键词提取 jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags
<span class="token number">3</span><span class="token punctuation">.</span>词性标注 jieba<span class="token punctuation">.</span>posseg<span class="token punctuation">.</span>cut
<span class="token number">4</span><span class="token punctuation">.</span>返回词语在原文的起止位置 jieba<span class="token punctuation">.</span>tokenize</code></pre>

<h2 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h2><p>将自己需要的分词的词语，加入自定义词典当中</p>
<blockquote>
<ul>
<li>开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率</li>
<li>用法： jieba.load_userdict(file_name) # file_name 为文件类对象或自定义词典的路径</li>
<li>词典格式和 <code>dict.txt</code> 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。<code>file_name</code> 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。</li>
<li>词频省略时使用自动计算的能保证分出该词的词频。</li>
</ul>
</blockquote>
<p>分为以下几步</p>
<ol>
<li><p>构建自定义词典为相应的格式 部分结果如下:</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token number">21</span><span class="token operator">-</span>羟化酶缺陷症
CO2潴留
E字征
HIV感染
Howship<span class="token operator">-</span>Romberg征
Korsakov综合征
Moro反应迟钝
Q<span class="token operator">-</span>T间期延长
畏寒</code></pre></li>
<li><p>调用相应的方法</p>
</li>
<li><p>测试相应的数据</p>
</li>
</ol>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span>
<span class="token keyword">from</span> __future__ <span class="token keyword">import</span> print_function<span class="token punctuation">,</span> unicode_literals
<span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">"../"</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> jieba
<span class="token keyword">import</span> jieba<span class="token punctuation">.</span>posseg <span class="token keyword">as</span> pseg
<span class="token keyword">import</span> os
path <span class="token operator">=</span> os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 添加用户词典</span>
jieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span>path <span class="token operator">+</span> <span class="token string">"\\userdict.txt"</span><span class="token punctuation">)</span>

test_sent <span class="token operator">=</span> <span class="token punctuation">(</span>
<span class="token string">"无畏寒一过性心尖部收缩期杂音测试"</span>
<span class="token punctuation">)</span>
words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>test_sent<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>

<p>添加前 无畏寒一过性心尖部收缩期杂音测试 =&gt; 无畏/寒一/过性/心尖/部/收缩期/杂音/测试 添加后 =&gt; 无畏/寒/一过性心尖部收缩期杂音/测试</p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>添加前后，jiaba分词能将<code>一过性心尖部收缩期杂音</code>分词成功，但是<code>无畏寒</code>没有成功，可能是因为无畏在系统中的频度较高，（词频省略时使用自动计算的能保证分出该词的词频。）而用户词典的词语频度相对较低。所以下一步，我将尝试提高用户词典频度，或者降低系统词典频度。如若不行，可进一步查看源码。</p>
<h3 id="继续测试"><a href="#继续测试" class="headerlink" title="继续测试"></a>继续测试</h3><pre class="language-python" data-language="python"><code class="language-python">jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span><span class="token string">'畏寒'</span><span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> tag<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token comment"># 通过添加畏寒的频度为10</span>
结果仍为<span class="token punctuation">:</span>无畏<span class="token operator">/</span>寒<span class="token operator">/</span>一过性心尖部收缩期杂音<span class="token operator">/</span>测试
jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span><span class="token string">'畏寒'</span><span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> tag<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token comment"># 添加畏寒的频度为100</span>
结果为<span class="token punctuation">:</span>无<span class="token operator">/</span>畏寒<span class="token operator">/</span>一过性心尖部收缩期杂音<span class="token operator">/</span>测试</code></pre>

<p>由上述结果可知确实若用户词典省略词频，则频度相对系统词典较低，无法正确分出结果，所以只需要在用户添加频度，并设置在100，便可以实现分词功能，但是不能确定是不是100就能覆盖所有的系统词汇，所以进一步查看系统词汇的词频。在源码中有<code>dict.txt</code>其中包含了所有的词语的系统词频，查看其中的最大值。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#encoding=utf-8</span>
<span class="token keyword">from</span> __future__ <span class="token keyword">import</span> print_function<span class="token punctuation">,</span> unicode_literals
<span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">"../"</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> jieba
<span class="token keyword">import</span> jieba<span class="token punctuation">.</span>posseg <span class="token keyword">as</span> pseg
<span class="token keyword">import</span> os
path <span class="token operator">=</span> os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 获取系统词典路径</span>
rpath <span class="token operator">=</span> path <span class="token operator">+</span> <span class="token string">"\\jieba\\dict.txt"</span>
<span class="token comment"># 读取词典 </span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
res <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>rpath<span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">,</span>header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">,</span><span class="token string">'frequence'</span><span class="token punctuation">,</span><span class="token string">'type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">[</span><span class="token string">'frequence'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 得到结果883634 ,也就是如果将词频设置为大于883634的数则用户词典绝对优先于系统词典</span></code></pre>

<p>设置代码如下</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token keyword">import</span> os
path  <span class="token operator">=</span> os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#获取当前工作路径</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span>
output_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'userdict.txt'</span><span class="token punctuation">)</span>

<span class="token comment"># 处理词典</span>
res <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'zhengzhuang.txt'</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">,</span>header <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">,</span><span class="token string">'type'</span><span class="token punctuation">,</span><span class="token string">'frequence'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

res <span class="token operator">=</span> res<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'type'</span><span class="token punctuation">,</span> <span class="token string">'frequence'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 添加频度</span>
res<span class="token punctuation">[</span><span class="token string">'frequence'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">883635</span>
<span class="token comment"># 转化为txt文件</span>
res<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>output_file<span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre>

<p>在添加症状的词条后测试如下</p>
<pre class="language-none"><code class="language-none">患者1月前无明显诱因及前驱症状下出现腹泻，起初稀便，后为水样便，无恶心呕吐，每日2-3次，无呕血，无腹痛，无畏寒寒战，无低热盗汗，无心悸心慌，无大汗淋漓，否认里急后重感，否认蛋花样大便，当时未重视，未就诊。
患者&#x2F;1&#x2F;月前&#x2F;无&#x2F;明显&#x2F;诱因&#x2F;及&#x2F;前驱&#x2F;症状&#x2F;下&#x2F;出现&#x2F;腹泻&#x2F;，&#x2F;起初&#x2F;稀便&#x2F;，&#x2F;后&#x2F;为&#x2F;水样便&#x2F;，&#x2F;无&#x2F;恶心&#x2F;呕吐&#x2F;，&#x2F;每日&#x2F;2&#x2F;-&#x2F;3&#x2F;次&#x2F;，&#x2F;无&#x2F;呕血&#x2F;，&#x2F;无&#x2F;腹痛&#x2F;，&#x2F;无&#x2F;畏寒&#x2F; 寒战&#x2F;，&#x2F;无&#x2F;低热&#x2F;盗汗&#x2F;，&#x2F;无&#x2F;心悸&#x2F;心慌&#x2F;，&#x2F;无&#x2F;大汗淋漓&#x2F;，&#x2F;否认&#x2F;里急后重&#x2F;感&#x2F;，&#x2F;否认&#x2F;蛋&#x2F;花样&#x2F;大便&#x2F;，&#x2F;当时&#x2F;未&#x2F;重视&#x2F;，&#x2F;未&#x2F;就诊&#x2F;。</code></pre>

<h2 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h2><p>查看源码，从cut入手一步步查看其内部如何调用的</p>
<pre class="language-python" data-language="python"><code class="language-python">__init__<span class="token punctuation">.</span>py
cut <span class="token operator">=</span> dt<span class="token punctuation">.</span>cut <span class="token comment"># cut为全局方法</span>
<span class="token comment"># 关键方法</span>
<span class="token keyword">def</span> <span class="token function">cut</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> use_paddle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        The main function that segments an entire sentence that contains
        Chinese characters into separated words.

        Parameter:
            - sentence: The str(unicode) to be segmented.
            - cut_all: Model type. True for full pattern, False for accurate pattern.
            - HMM: Whether to use the Hidden Markov Model.
        """</span>
         <span class="token comment"># 判断是存在paddle</span>
        is_paddle_installed <span class="token operator">=</span> check_paddle_install<span class="token punctuation">[</span><span class="token string">'is_paddle_installed'</span><span class="token punctuation">]</span>
        <span class="token comment"># 转码，英文utf8 中文gbk</span>
        sentence <span class="token operator">=</span> strdecode<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
        <span class="token comment"># paddle相关</span>
        <span class="token keyword">if</span> use_paddle <span class="token keyword">and</span> is_paddle_installed<span class="token punctuation">:</span>
            <span class="token comment"># if sentence is null, it will raise core exception in paddle.</span>
            <span class="token keyword">if</span> sentence <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">return</span>
            <span class="token keyword">import</span> jieba<span class="token punctuation">.</span>lac_small<span class="token punctuation">.</span>predict <span class="token keyword">as</span> predict
            results <span class="token operator">=</span> predict<span class="token punctuation">.</span>get_sent<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
            <span class="token keyword">for</span> sent <span class="token keyword">in</span> results<span class="token punctuation">:</span>
                <span class="token keyword">if</span> sent <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                <span class="token keyword">yield</span> sent
            <span class="token keyword">return</span>
        
        re_han <span class="token operator">=</span> re_han_default
        re_skip <span class="token operator">=</span> re_skip_default
        <span class="token comment"># 判断cut 模式</span>
        <span class="token keyword">if</span> cut_all<span class="token punctuation">:</span>
            cut_block <span class="token operator">=</span> self<span class="token punctuation">.</span>__cut_all <span class="token comment"># 全模式</span>
        <span class="token keyword">elif</span> HMM<span class="token punctuation">:</span>
            cut_block <span class="token operator">=</span> self<span class="token punctuation">.</span>__cut_DAG <span class="token comment"># HMM模型 默认为这种</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            cut_block <span class="token operator">=</span> self<span class="token punctuation">.</span>__cut_DAG_NO_HMM <span class="token comment"># 无HMM模型</span>
        
        blocks <span class="token operator">=</span> re_han<span class="token punctuation">.</span>split<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>  <span class="token comment"># 正则表达式获取相应的字符串 现根据标点符号分词</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>blocks<span class="token punctuation">)</span>
        <span class="token keyword">for</span> blk <span class="token keyword">in</span> blocks<span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token keyword">not</span> blk<span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            <span class="token keyword">if</span> re_han<span class="token punctuation">.</span>match<span class="token punctuation">(</span>blk<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 没有空格</span>
                <span class="token keyword">for</span> word <span class="token keyword">in</span> cut_block<span class="token punctuation">(</span>blk<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">yield</span> word
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                tmp <span class="token operator">=</span> re_skip<span class="token punctuation">.</span>split<span class="token punctuation">(</span>blk<span class="token punctuation">)</span> <span class="token comment"># 去空格</span>
                <span class="token keyword">for</span> x <span class="token keyword">in</span> tmp<span class="token punctuation">:</span>
                    <span class="token keyword">if</span> re_skip<span class="token punctuation">.</span>match<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
                        <span class="token keyword">yield</span> x
                    <span class="token keyword">elif</span> <span class="token keyword">not</span> cut_all<span class="token punctuation">:</span>
                        <span class="token keyword">for</span> xx <span class="token keyword">in</span> x<span class="token punctuation">:</span>
                            <span class="token keyword">yield</span> xx
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        <span class="token keyword">yield</span> x</code></pre>

<p>由上述代码可知默认的模型__cut_DAG, 输入的字符串，首先根据标点符号分词，然后cut_block负责处理每一个初步拆分过后的字符串，具体的拆分方法为以下两个函数</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 得到的最大概率路径的概率。这里即为动态规划查找最大概率路径</span>
   <span class="token keyword">def</span> <span class="token function">calc</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">,</span> DAG<span class="token punctuation">,</span> route<span class="token punctuation">)</span><span class="token punctuation">:</span>
       N <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
       route<span class="token punctuation">[</span>N<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
       <span class="token comment"># 通过词频搜索</span>
       logtotal <span class="token operator">=</span> log<span class="token punctuation">(</span>self<span class="token punctuation">.</span>total<span class="token punctuation">)</span> <span class="token comment">#利用total进行动态规划</span>
       <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">xrange</span><span class="token punctuation">(</span>N <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
           route<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">(</span>log<span class="token punctuation">(</span>self<span class="token punctuation">.</span>FREQ<span class="token punctuation">.</span>get<span class="token punctuation">(</span>sentence<span class="token punctuation">[</span>idx<span class="token punctuation">:</span>x <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span>
                             logtotal <span class="token operator">+</span> route<span class="token punctuation">[</span>x <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> DAG<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span>

   <span class="token comment"># 函数功能为把输入的句子生成有向无环图, 得到所有可能的词语</span>
   <span class="token keyword">def</span> <span class="token function">get_DAG</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
       self<span class="token punctuation">.</span>check_initialized<span class="token punctuation">(</span><span class="token punctuation">)</span>
       DAG <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
       N <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
       <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">xrange</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
           tmplist <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
           i <span class="token operator">=</span> k
           frag <span class="token operator">=</span> sentence<span class="token punctuation">[</span>k<span class="token punctuation">]</span>
           <span class="token keyword">while</span> i <span class="token operator">&lt;</span> N <span class="token keyword">and</span> frag <span class="token keyword">in</span> self<span class="token punctuation">.</span>FREQ<span class="token punctuation">:</span> <span class="token comment"># 查询FREQ中的词</span>
               <span class="token keyword">if</span> self<span class="token punctuation">.</span>FREQ<span class="token punctuation">[</span>frag<span class="token punctuation">]</span><span class="token punctuation">:</span>
                   tmplist<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
               i <span class="token operator">+=</span> <span class="token number">1</span>
               frag <span class="token operator">=</span> sentence<span class="token punctuation">[</span>k<span class="token punctuation">:</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
           <span class="token keyword">if</span> <span class="token keyword">not</span> tmplist<span class="token punctuation">:</span>
               tmplist<span class="token punctuation">.</span>append<span class="token punctuation">(</span>k<span class="token punctuation">)</span>
           DAG<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> tmplist
       <span class="token keyword">return</span> DAG</code></pre>

<p>由此可知FREQ和total是函数计算的关键，所以找到FREQ和total是如何初始化的就可以明白计算的依据了</p>
<pre class="language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>FREQ<span class="token punctuation">,</span> self<span class="token punctuation">.</span>total <span class="token operator">=</span> self<span class="token punctuation">.</span>gen_pfdict<span class="token punctuation">(</span>self<span class="token punctuation">.</span>get_dict_file<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 得到词语和词频</span>
 <span class="token comment"># 通过get_dict_file获得</span>
 <span class="token keyword">def</span> <span class="token function">get_dict_file</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token keyword">if</span> self<span class="token punctuation">.</span>dictionary <span class="token operator">==</span> DEFAULT_DICT<span class="token punctuation">:</span>
           <span class="token keyword">return</span> get_module_res<span class="token punctuation">(</span>DEFAULT_DICT_NAME<span class="token punctuation">)</span>
       <span class="token keyword">else</span><span class="token punctuation">:</span>
           <span class="token keyword">return</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dictionary<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span>
 <span class="token comment"># 默认为该目录下的dict.txt</span>
 DEFAULT_DICT_NAME <span class="token operator">=</span> <span class="token string">"dict.txt"</span></code></pre>

<p>上述推理可知，是dict.txt中的词语和词频，通过有向无环图和动态规划路径得到分词结果，而在之前通过用户词典调用的方法无非就是在此基础上加上新的词语和词频。</p>
<pre class="language-python" data-language="python"><code class="language-python">   <span class="token keyword">def</span> <span class="token function">load_userdict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> f<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token triple-quoted-string string">'''
       Load personalized dict to improve detect rate.

       Parameter:
           - f : A plain text file contains words and their ocurrences.
                 Can be a file-like object, or the path of the dictionary file,
                 whose encoding must be utf-8.

       Structure of dict file:
       word1 freq1 word_type1
       word2 freq2 word_type2
       ...
       Word type may be ignored
       '''</span>
       self<span class="token punctuation">.</span>check_initialized<span class="token punctuation">(</span><span class="token punctuation">)</span>
       <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> string_types<span class="token punctuation">)</span><span class="token punctuation">:</span>
           f_name <span class="token operator">=</span> f
           f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span>
       <span class="token keyword">else</span><span class="token punctuation">:</span>
           f_name <span class="token operator">=</span> resolve_filename<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
       <span class="token keyword">for</span> lineno<span class="token punctuation">,</span> ln <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
           line <span class="token operator">=</span> ln<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
           <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>line<span class="token punctuation">,</span> text_type<span class="token punctuation">)</span><span class="token punctuation">:</span>
               <span class="token keyword">try</span><span class="token punctuation">:</span>
                   line <span class="token operator">=</span> line<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>lstrip<span class="token punctuation">(</span><span class="token string">'\ufeff'</span><span class="token punctuation">)</span>
               <span class="token keyword">except</span> UnicodeDecodeError<span class="token punctuation">:</span>
                   <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'dictionary file %s must be utf-8'</span> <span class="token operator">%</span> f_name<span class="token punctuation">)</span>
           <span class="token keyword">if</span> <span class="token keyword">not</span> line<span class="token punctuation">:</span>
               <span class="token keyword">continue</span>
           <span class="token comment"># match won't be None because there's at least one character</span>
           word<span class="token punctuation">,</span> freq<span class="token punctuation">,</span> tag <span class="token operator">=</span> re_userdict<span class="token punctuation">.</span>match<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">.</span>groups<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 得到用户词典词语和词频</span>
           <span class="token keyword">if</span> freq <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
               freq <span class="token operator">=</span> freq<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
           <span class="token keyword">if</span> tag <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
               tag <span class="token operator">=</span> tag<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
           self<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span>word<span class="token punctuation">,</span> freq<span class="token punctuation">,</span> tag<span class="token punctuation">)</span> <span class="token comment"># 添加到词典中</span>
<span class="token keyword">def</span> <span class="token function">add_word</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word<span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> tag<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token triple-quoted-string string">"""
       Add a word to dictionary.

       freq and tag can be omitted, freq defaults to be a calculated value
       that ensures the word can be cut out.
       """</span>
       self<span class="token punctuation">.</span>check_initialized<span class="token punctuation">(</span><span class="token punctuation">)</span>
       word <span class="token operator">=</span> strdecode<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
       freq <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>freq<span class="token punctuation">)</span> <span class="token keyword">if</span> freq <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">else</span> self<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
       <span class="token comment"># 添加词</span>
       self<span class="token punctuation">.</span>FREQ<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> freq
       self<span class="token punctuation">.</span>total <span class="token operator">+=</span> freq
       <span class="token keyword">if</span> tag<span class="token punctuation">:</span>
           self<span class="token punctuation">.</span>user_word_tag_tab<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> tag
       <span class="token keyword">for</span> ch <span class="token keyword">in</span> <span class="token builtin">xrange</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
           wfrag <span class="token operator">=</span> word<span class="token punctuation">[</span><span class="token punctuation">:</span>ch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
           <span class="token keyword">if</span> wfrag <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>FREQ<span class="token punctuation">:</span>
               self<span class="token punctuation">.</span>FREQ<span class="token punctuation">[</span>wfrag<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
       <span class="token keyword">if</span> freq <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
           finalseg<span class="token punctuation">.</span>add_force_split<span class="token punctuation">(</span>word<span class="token punctuation">)</span></code></pre>

<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><div style="background:yellow"><strong> 构建一个用户词典表，然后将词语的词频设置为大于883634的数，则用户词典绝对优先于系统词典，其中的工程量主要在如何构造一个合适的字典，在通过调用`load_userdict` 方法，在用`cut`方法即可得到设置后的结果，具体操作见方案一。接下来的研究目标：1.用户词典大小最大可以有多大 2.用户词典大小对速度的影响 3.有相同前缀和后缀的词汇如何区分 4. 和百度分词的API对比 </strong></div>。

</div></section></article><div class="post-nav"><div class="post-nav-item"></div><div class="post-nav-item"><a class="post-nav-next" href="/2021/10/24/%E5%BF%85%E8%83%8C%E7%9F%A5%E8%AF%86%E7%82%B9/" rel="next" title="必背知识点"><span class="post-nav-text">必背知识点</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br></div><div id="waline"></div><script>Yun.utils.getScript("https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js", () => {
  const walineConfig = {"enable":true,"serverURL":"https://comment-one.vercel.app/","comment":true,"visitor":true,"el":"#waline","lang":"zh-CN"}
  walineConfig.path = "/2021/11/05/jieba%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E8%AF%8D%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"
  new Waline(walineConfig)
}, window.Waline);</script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 个人介绍</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v5.4.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.6.1</span></div><div id="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv" title="总访客量"><span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-user-line"></use></svg></span><span id="busuanzi_value_site_uv"></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv" title="总访问量"><span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg></span><span id="busuanzi_value_site_pv"></span></span></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><div id="aplayer"></div><script>window.addEventListener("DOMContentLoaded", () => {
  const ap = new APlayer({
    container: document.getElementById('aplayer'),
    fixed: true,
    autoplay: false,
    theme: "#0078E7",
    loop: "all",
    order: "list",
    preload: "auto",
    audio: [{"name":"星宿计时","artist":"杉田朗/洛天依","url":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/audio/star-timer.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"红昭愿","artist":"天真派","url":"http://music.163.com/song/media/outer/url?id=864648569.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"克罗地亚狂想曲","artist":"钢琴版","url":"http://music.163.com/song/media/outer/url?id=573093480.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"光年之外","artist":"邓紫棋","url":"http://music.163.com/song/media/outer/url?id=486194122.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"黑暗森林","artist":"逻辑","url":"http://music.163.com/song/media/outer/url?id=1447740748.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"虞姬叹","artist":"闻人听書_","url":"http://music.163.com/song/media/outer/url?id=1479526505.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"夜航星","artist":"章北海","url":"http://music.163.com/song/media/outer/url?id=1431292823.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"囍（女生版）","artist":"等什么君","url":"http://music.163.com/song/media/outer/url?id=1496822949.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"那些年","artist":"胡夏","url":"http://music.163.com/song/media/outer/url?id=25638810.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"年少有为","artist":"李荣浩","url":"http://music.163.com/song/media/outer/url?id=1293886117.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"赤伶","artist":"李玉刚","url":"http://music.163.com/song/media/outer/url?id=1454730043.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"Rubi3","artist":"周深","url":"http://music.163.com/song/media/outer/url?id=1815684465.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"大鱼","artist":"周深","url":"http://music.163.com/song/media/outer/url?id=1421191783.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"起风了","artist":"买辣椒也用券","url":"http://music.163.com/song/media/outer/url?id=1330348068.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"}],
    volume: 0.7,
    mutex: true,
    lrcType: 0,
    listFolded: true,
    listMaxHeight: "90",
    storageName: "aplayer-setting"
  });
});</script></div><!-- hexo injector body_end start --><script src="https://cdn.jsdelivr.net/npm/hexo-widget-tree@0.1.1/js/index.js"></script><div id="widget-tree">
      <ul><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/java/">java</a><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/java/javaweb/">javaweb</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/10/22/javaweb/" title="javaweb"><i class="post-icon gg-file-document"></i>javaweb</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%8B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">博客建立问题解决方法和使用方法</a><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%8B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/hexo%E7%9A%84%E4%BD%BF%E7%94%A8/">hexo的使用</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/14/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/" title="hexo的使用"><i class="post-icon gg-file-document"></i>hexo的使用</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%8B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E9%97%AE%E9%A2%98/">图片加载问题</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/17/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E9%97%AE%E9%A2%98/" title="图片加载问题"><i class="post-icon gg-file-document"></i>图片加载问题</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/knn/">knn</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/30/KNN%E4%B8%B4%E8%BF%91%E7%AE%97%E6%B3%95/" title="KNN临近算法"><i class="post-icon gg-file-document"></i>KNN临近算法</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/02/knn%E5%AE%9E%E6%88%98%E5%88%A4%E6%96%AD0-9/" title="knn实战判断0-9"><i class="post-icon gg-file-document"></i>knn实战判断0-9</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/">公式推导</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/18/%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E7%9A%84%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B/" title="正规方程的推导过程"><i class="post-icon gg-file-document"></i>正规方程的推导过程</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/">梯度下降&正规方程</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" title="多变量线性回归"><i class="post-icon gg-file-document"></i>多变量线性回归</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/17/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0and%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/" title="代价函数and梯度下降算法"><i class="post-icon gg-file-document"></i>代价函数and梯度下降算法</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/">自然语言</a><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/jieba/">jieba</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/11/05/jieba%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E8%AF%8D%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/" title="jieba使用教程---自定义分词不起作用解决方法"><i class="post-icon gg-file-document"></i>jieba使用教程---自定义分词不起作用解决方法</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E9%AB%98%E6%95%B0%E5%A4%8D%E4%B9%A0/">高数复习</a><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E9%AB%98%E6%95%B0%E5%A4%8D%E4%B9%A0/30%E8%AE%B2/">30讲</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/01/%E7%AC%AC%E4%B8%80%E8%AE%B2%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" title="第一讲高等数学基础知识"><i class="post-icon gg-file-document"></i>第一讲高等数学基础知识</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E9%AB%98%E6%95%B0%E5%A4%8D%E4%B9%A0/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/02/%E6%95%B0%E5%88%97/" title="数列"><i class="post-icon gg-file-document"></i>数列</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E9%AB%98%E6%95%B0%E5%A4%8D%E4%B9%A0/%E6%95%B4%E7%90%86%E7%AC%94%E8%AE%B0/">整理笔记</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/10/15/%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" title="一些基础知识"><i class="post-icon gg-file-document"></i>一些基础知识</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/10/24/%E5%BF%85%E8%83%8C%E7%9F%A5%E8%AF%86%E7%82%B9/" title="必背知识点"><i class="post-icon gg-file-document"></i>必背知识点</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/10/12/%E9%94%99%E9%A2%98%E6%9C%AC/" title="错题本"><i class="post-icon gg-file-document"></i>错题本</a></li></ul></li></ul></li></ul>
        <div id="widget-tree-button">
          <i class="gg-chevron-right"></i>
        </div>
      </div><!-- hexo injector body_end end --></body></html>