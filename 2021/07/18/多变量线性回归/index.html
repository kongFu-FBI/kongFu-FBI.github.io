<!DOCTYPE html><html lang="zh-CN"><head><!-- hexo injector head_begin start --><link href="https://cdn.jsdelivr.net/npm/hexo-widget-tree@0.1.1/css/index.css" rel="stylesheet"/><!-- hexo injector head_begin end --><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="个人介绍"><meta name="copyright" content="个人介绍"><meta name="generator" content="Hexo 5.4.0"><meta name="theme" content="hexo-theme-yun"><title>多变量线性回归 | 本站介绍</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.24/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_j5gk85dg4pf.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", () => {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
});
</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script>document.addEventListener("DOMContentLoaded", () => {
  Yun.utils.renderKatex();
});</script><link class="aplayer-style-marker" rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script class="aplayer-script-marker" src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" defer></script><script class="meting-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/pjax@latest/pjax.min.js" defer></script><script src="/js/pjax.js" defer></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><link id="light-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism.css" media="(prefers-color-scheme: light)"><link id="dark-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism-tomorrow.css" media="(prefers-color-scheme: dark)"><link rel="icon" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"example.com","root":"/","title":"达拉崩吧的城堡","version":"1.6.1","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><meta name="description" content="多维特征目前为止，我们探讨了单变量&#x2F;特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为(x1,x2,x3,…..xn)  增添更多特征后，我们引入一系列新的注释： n 代表特征的数量 x^(i)代表第 i 个训练实例，是特征矩阵中的第i行，是一个向量（vector）。 例如：  代表特征矩阵中第 i 行的第 j 个特征，也就是第 i 个训">
<meta property="og:type" content="article">
<meta property="og:title" content="多变量线性回归">
<meta property="og:url" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/index.html">
<meta property="og:site_name" content="本站介绍">
<meta property="og:description" content="多维特征目前为止，我们探讨了单变量&#x2F;特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为(x1,x2,x3,…..xn)  增添更多特征后，我们引入一系列新的注释： n 代表特征的数量 x^(i)代表第 i 个训练实例，是特征矩阵中的第i行，是一个向量（vector）。 例如：  代表特征矩阵中第 i 行的第 j 个特征，也就是第 i 个训">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/591785837c95bca369021efa14a8bb1c.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/123.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719150212096.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153310324.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153559772.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153714444.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153736056.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153809344.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153829268.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153847913.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719154059462.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719154114828.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/966e5a9b00687678374b8221fdd33475.jpg">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/b8167ff0926046e112acf789dba98057.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719160000466.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719160019177.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719160031990.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719160141106.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/cd4e3df45c34f6a8e2bb7cd3a2849e6c.jpg">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171038844.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171111413.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171224651.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171243522.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171256598.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171309347.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171327390.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171352562.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171446226.png">
<meta property="og:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171507131.png">
<meta property="article:published_time" content="2021-07-18T08:20:32.000Z">
<meta property="article:modified_time" content="2021-07-20T08:05:15.385Z">
<meta property="article:author" content="个人介绍">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/591785837c95bca369021efa14a8bb1c.png"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><canvas id="trianglifyContainer"></canvas><script defer src="https://cdn.jsdelivr.net/npm/trianglify@4/dist/trianglify.bundle.js"></script><script>document.addEventListener("DOMContentLoaded", () => {
  const pattern = trianglify({
    width: 800,
    height: 600,
    cellSize: 75,
    palette: ["YlGnBu", "GnBu", "Purples", "Blues"],
  });
  const canvasOpts = {
    applyCssScaling: false
  }
  document.body.appendChild(pattern.toCanvas(trianglifyContainer, canvasOpts));
});</script><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="个人介绍"><img width="96" loading="lazy" src="/images/hade.jpg" alt="个人介绍"><span class="site-author-status" title="不想上学">😭</span></a><div class="site-author-name"><a href="/about/">个人介绍</a></div><a class="site-name" href="/about/site.html">本站介绍</a><sub class="site-subtitle"></sub><div class="site-desciption"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">9</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">10</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">0</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="http://wpa.qq.com/msgrd?v=3&amp;uin=644907106&amp;site=qq&amp;menu=yes" title="QQ" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/kongFu-FBI" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:644907106@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/215083917" title="哔哩哔哩动画" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81"><span class="toc-number">1.</span> <span class="toc-text">多维特征</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%8F%98%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">1.1.</span> <span class="toc-text">多变量梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%AE%9E%E8%B7%B51-%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE"><span class="toc-number">1.2.</span> <span class="toc-text">梯度下降法实践1-特征缩放</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%AE%9E%E8%B7%B52-%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="toc-number">1.3.</span> <span class="toc-text">梯度下降法实践2-学习率</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B-%E9%87%8D%E7%82%B9"><span class="toc-number">2.</span> <span class="toc-text">正规方程(重点)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E7%9A%84%E6%8E%A8%E5%AF%BC-%E2%80%94%E2%80%94-gt"><span class="toc-number">2.1.</span> <span class="toc-text">正规方程的推导 ——&gt;正规方程的推导过程</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://example.com/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="个人介绍"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="本站介绍"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">多变量线性回归</h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2021-07-18 16:20:32" itemprop="dateCreated datePublished" datetime="2021-07-18T16:20:32+08:00">2021-07-18</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <time title="修改时间：2021-07-20 16:05:15" itemprop="dateModified" datetime="2021-07-20T16:05:15+08:00">2021-07-20</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">1.6k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">5m</span></span></span><span class="post-busuanzi"><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span id="busuanzi_value_page_pv"></span></span></span><span class="leancloud_visitors" id="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" data-flag-title="多变量线性回归"><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><span class="post-meta-divider">-</span><a href="#comment"><span class="post-meta-item-icon" title="评论数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-chat-3-line"></use></svg> <span class="waline-comment-count" id="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"></span></span></a><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">机器学习</span></a></span> > <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">梯度下降&amp;正规方程</span></a></span></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><h1 id="多维特征"><a href="#多维特征" class="headerlink" title="多维特征"></a>多维特征</h1><p>目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为(x1,x2,x3,…..xn)</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/591785837c95bca369021efa14a8bb1c.png" alt="591785837c95bca369021efa14a8bb1c" loading="lazy"></p>
<p>增添更多特征后，我们引入一系列新的注释：</p>
<p>n 代表特征的数量</p>
<p>x^(i)代表第 i 个训练实例，是特征矩阵中的第i行，是一个<strong>向量</strong>（<strong>vector</strong>）。</p>
<p>例如：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/123.png" alt="屏幕截图 2021-07-19 150052" loading="lazy"></p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719150212096.png" alt="image-20210719150212096" loading="lazy">代表特征矩阵中第 i 行的第 j 个特征，也就是第 i 个训练实例的第 j 个特征。</p>
<p>支持多变量的假设 h 表示为 ：<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153310324.png" alt="image-20210719153310324" loading="lazy">，</p>
<p>这个公式中有 n+1 个参数和 n 个变量，为了使得公式能够简化一些，引入 x0=1 ，则公式转化为：![image-20210719153435656.png)</p>
<p>此时模型中的参数是一个 n+1 维的向量，任何一个训练实例也都是 n+1 维的向量，特征矩阵 X 的维度是  m*(n+1)。 因此公式可以简化为：<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153559772.png" alt="image-20210719153559772" loading="lazy">，其中上标 T 代表矩阵转置。</p>
<h2 id="多变量梯度下降"><a href="#多变量梯度下降" class="headerlink" title="多变量梯度下降"></a>多变量梯度下降</h2><p>在多变量线性回归中，构建一个代价函数，则这个代价函数是所有建模误差的平方和，即： <img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153714444.png" alt="image-20210719153714444" loading="lazy">，</p>
<p>其中：<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153736056.png" alt="image-20210719153736056" loading="lazy"></p>
<p>故而多变量线性回归的批量梯度下降算法为：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153809344.png" alt="image-20210719153809344" loading="lazy"></p>
<p>即：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153829268.png" alt="image-20210719153829268" loading="lazy"></p>
<p>求导数后得到：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719153847913.png" alt="image-20210719153847913" loading="lazy"></p>
<p>![屏幕截图 2021-07-19 154000](屏幕截图 2021-07-19 154000.png)</p>
<p>（注意：不要忘记 *xj^i ）</p>
<p>我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。</p>
<p>代码示例：</p>
<p>计算代价函数 <img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719154059462.png" alt="image-20210719154059462" loading="lazy"> 其中 <img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719154114828.png" alt="image-20210719154114828" loading="lazy">：</p>
<p><strong>Python</strong> 代码：</p>
<pre class="language-none"><code class="language-none">def computeCost(X, y, theta):
    inner &#x3D; np.power(((X * theta.T) - y), 2)
    return np.sum(inner) &#x2F; (2 * len(X))</code></pre>

<h2 id="梯度下降法实践1-特征缩放"><a href="#梯度下降法实践1-特征缩放" class="headerlink" title="梯度下降法实践1-特征缩放"></a>梯度下降法实践1-特征缩放</h2><p>在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。</p>
<p>以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/966e5a9b00687678374b8221fdd33475.jpg" alt="966e5a9b00687678374b8221fdd33475" loading="lazy"></p>
<p>解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/b8167ff0926046e112acf789dba98057.png" alt="b8167ff0926046e112acf789dba98057" loading="lazy"></p>
<p>最简单的方法是令：<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719160000466.png" alt="image-20210719160000466" loading="lazy">，其中 <img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719160019177.png" alt="image-20210719160019177" loading="lazy">是平均值，<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719160031990.png" alt="image-20210719160031990" loading="lazy">是标准差(或者最大值 - 最小值)</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719160141106.png" alt="image-20210719160141106" loading="lazy"></p>
<p><u>特征缩放不需要特别的精准，只是为了让梯度下降更加快速</u></p>
<h2 id="梯度下降法实践2-学习率"><a href="#梯度下降法实践2-学习率" class="headerlink" title="梯度下降法实践2-学习率"></a>梯度下降法实践2-学习率</h2><p>梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/cd4e3df45c34f6a8e2bb7cd3a2849e6c.jpg" alt="cd4e3df45c34f6a8e2bb7cd3a2849e6c" loading="lazy"></p>
<p>也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好。</p>
<div style="background:yellow"><strong>
梯度下降算法的每次迭代受到学习率的影响，如果学习率 a 过小，则达到收敛所需的迭代次数会非常高；
   </strong></div>
<div style="background:green"><strong>
如果学习率 a 过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛
    </strong></div>


<p>通常可以考虑尝试些学习率：</p>
<p>a = 0.01,0.03,0.1</p>
<h1 id="正规方程-重点"><a href="#正规方程-重点" class="headerlink" title="正规方程(重点)"></a>正规方程(重点)</h1><p>对于某些线性回归问题，正规方程方法是更好的解决方案。如：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171038844.png" alt="image-20210719171038844" loading="lazy"></p>
<p>正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171111413.png" alt="image-20210719171111413" loading="lazy">。假设我们的训练集特征矩阵为 X（包含x0 = 1)  并且我们的训练集结果为向量 y ，则利用正规方程解出向量 <img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171224651.png" alt="image-20210719171224651" loading="lazy"> 。 上标<strong>T</strong>代表矩阵转置，上标-1 代表矩阵的逆。设矩阵<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171243522.png" alt="image-20210719171243522" loading="lazy">，则：<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171256598.png" alt="image-20210719171256598" loading="lazy"> 以下表示数据为例：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171309347.png" alt="image-20210719171309347" loading="lazy"></p>
<p>即：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171327390.png" alt="image-20210719171327390" loading="lazy"></p>
<p>运用正规方程方法求解参数：</p>
<p><img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171352562.png" alt="image-20210719171352562" loading="lazy"></p>
<p>注：对于那些不可逆的矩阵（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），正规方程方法是不能用的。</p>
<p>梯度下降与正规方程的比较：</p>
<table>
<thead>
<tr>
<th align="left">梯度下降</th>
<th align="left">正规方程</th>
</tr>
</thead>
<tbody><tr>
<td align="left">需要选择学习率a</td>
<td align="left">不需要</td>
</tr>
<tr>
<td align="left">需要多次迭代</td>
<td align="left">一次运算得出</td>
</tr>
<tr>
<td align="left">当特征数量n大时也能较好适用</td>
<td align="left">需要计算 <img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171446226.png" alt="image-20210719171446226" loading="lazy"> 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为<img src="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/image-20210719171507131.png" alt="image-20210719171507131" loading="lazy">，通常来说当n小于10000 时还是可以接受的</td>
</tr>
<tr>
<td align="left">适用于各种类型的模型</td>
<td align="left">只适用于线性模型，不适合逻辑回归模型等其他模型</td>
</tr>
</tbody></table>
<p>总结一下，只要特征变量的数目并不大，标准方程是一个很好的计算参数的替代方法。具体地说，只要特征变量数量小于一万，我通常使用标准方程法，而不使用梯度下降法。</p>
<p>随着我们要讲的学习算法越来越复杂，例如，当我们讲到分类算法，像逻辑回归算法，我们会看到，实际上对于那些算法，并不能使用标准方程法。对于那些更复杂的学习算法，我们将不得不仍然使用梯度下降法。因此，梯度下降法是一个非常有用的算法，可以用在有大量特征变量的线性回归问题。或者我们以后在课程中，会讲到的一些其他的算法，因为标准方程法不适合或者不能用在它们上。但对于这个特定的线性回归模型，标准方程法是一个比梯度下降法更快的替代算法。所以，根据具体的问题，以及你的特征变量的数量，这两种算法都是值得学习的。</p>
<p>正规方程的<strong>python</strong>实现：</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
    
 <span class="token keyword">def</span> <span class="token function">normalEqn</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
   theta <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T@X<span class="token punctuation">)</span>@X<span class="token punctuation">.</span>T@y <span class="token comment"># X.T@X等价于X.T.dot(X)</span>
    
   <span class="token keyword">return</span> theta</code></pre>



<h2 id="正规方程的推导-——-gt"><a href="#正规方程的推导-——-gt" class="headerlink" title="正规方程的推导 ——&gt;"></a>正规方程的推导 ——&gt;<a href="/2021/07/18/%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E7%9A%84%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B/" title="正规方程的推导过程">正规方程的推导过程</a></h2></div></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2021/07/18/%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E7%9A%84%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B/" rel="prev" title="正规方程的推导过程"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">正规方程的推导过程</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2021/07/17/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E9%97%AE%E9%A2%98/" rel="next" title="图片加载问题"><span class="post-nav-text">图片加载问题</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br></div><div id="waline"></div><script>Yun.utils.getScript("https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js", () => {
  const walineConfig = {"enable":true,"serverURL":"https://comment-one.vercel.app/","comment":true,"visitor":true,"el":"#waline","lang":"zh-CN"}
  walineConfig.path = "/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"
  new Waline(walineConfig)
}, window.Waline);</script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 个人介绍</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v5.4.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.6.1</span></div><div id="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv" title="总访客量"><span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-user-line"></use></svg></span><span id="busuanzi_value_site_uv"></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv" title="总访问量"><span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg></span><span id="busuanzi_value_site_pv"></span></span></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><div id="aplayer"></div><script>window.addEventListener("DOMContentLoaded", () => {
  const ap = new APlayer({
    container: document.getElementById('aplayer'),
    fixed: true,
    autoplay: false,
    theme: "#0078E7",
    loop: "all",
    order: "list",
    preload: "auto",
    audio: [{"name":"星宿计时","artist":"杉田朗/洛天依","url":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/audio/star-timer.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"红昭愿","artist":"天真派","url":"http://music.163.com/song/media/outer/url?id=864648569.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"克罗地亚狂想曲","artist":"钢琴版","url":"http://music.163.com/song/media/outer/url?id=573093480.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"光年之外","artist":"邓紫棋","url":"http://music.163.com/song/media/outer/url?id=486194122.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"黑暗森林","artist":"逻辑","url":"http://music.163.com/song/media/outer/url?id=1447740748.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"虞姬叹","artist":"闻人听書_","url":"http://music.163.com/song/media/outer/url?id=1479526505.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"夜航星","artist":"章北海","url":"http://music.163.com/song/media/outer/url?id=1431292823.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"囍（女生版）","artist":"等什么君","url":"http://music.163.com/song/media/outer/url?id=1496822949.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"那些年","artist":"胡夏","url":"http://music.163.com/song/media/outer/url?id=25638810.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"年少有为","artist":"李荣浩","url":"http://music.163.com/song/media/outer/url?id=1293886117.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"赤伶","artist":"李玉刚","url":"http://music.163.com/song/media/outer/url?id=1454730043.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"Rubi3","artist":"周深","url":"http://music.163.com/song/media/outer/url?id=1815684465.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"大鱼","artist":"周深","url":"http://music.163.com/song/media/outer/url?id=1421191783.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"},{"name":"起风了","artist":"买辣椒也用券","url":"http://music.163.com/song/media/outer/url?id=1330348068.mp3","cover":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/bg/stars-timing-0.jpg"}],
    volume: 0.7,
    mutex: true,
    lrcType: 0,
    listFolded: true,
    listMaxHeight: "90",
    storageName: "aplayer-setting"
  });
});</script></div><!-- hexo injector body_end start --><script src="https://cdn.jsdelivr.net/npm/hexo-widget-tree@0.1.1/js/index.js"></script><div id="widget-tree">
      <ul><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%8B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">博客建立问题解决方法和使用方法</a><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%8B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/hexo%E7%9A%84%E4%BD%BF%E7%94%A8/">hexo的使用</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/14/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/" title="hexo的使用"><i class="post-icon gg-file-document"></i>hexo的使用</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E7%AB%8B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E9%97%AE%E9%A2%98/">图片加载问题</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/17/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E9%97%AE%E9%A2%98/" title="图片加载问题"><i class="post-icon gg-file-document"></i>图片加载问题</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/knn/">knn</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/30/KNN%E4%B8%B4%E8%BF%91%E7%AE%97%E6%B3%95/" title="KNN临近算法"><i class="post-icon gg-file-document"></i>KNN临近算法</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/02/knn%E5%AE%9E%E6%88%98%E5%88%A4%E6%96%AD0-9/" title="knn实战判断0-9"><i class="post-icon gg-file-document"></i>knn实战判断0-9</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/">公式推导</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/18/%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E7%9A%84%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B/" title="正规方程的推导过程"><i class="post-icon gg-file-document"></i>正规方程的推导过程</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/">梯度下降&正规方程</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/18/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" title="多变量线性回归"><i class="post-icon gg-file-document"></i>多变量线性回归</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/07/17/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0and%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/" title="代价函数and梯度下降算法"><i class="post-icon gg-file-document"></i>代价函数and梯度下降算法</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E9%AB%98%E6%95%B0%E5%A4%8D%E4%B9%A0/">高数复习</a><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i><a class="tree-list-link" href="/categories/%E9%AB%98%E6%95%B0%E5%A4%8D%E4%B9%A0/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/2021/08/02/%E6%95%B0%E5%88%97/" title="数列"><i class="post-icon gg-file-document"></i>数列</a></li></ul></li></ul></li></ul>
        <div id="widget-tree-button">
          <i class="gg-chevron-right"></i>
        </div>
      </div><!-- hexo injector body_end end --></body></html>